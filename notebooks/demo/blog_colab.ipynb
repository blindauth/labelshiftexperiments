{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:basepair]",
      "language": "python",
      "name": "conda-env-basepair-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "blog_colab.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kundajelab/labelshiftexperiments/blob/master/notebooks/demo/blog_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEGggxiZWf1R"
      },
      "source": [
        "## This notebook demonstrates how to perform label shift domain adaptation using Maximum Likelihood + Bias-Corrected Temperature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toUqiI6MXvVh"
      },
      "source": [
        "Install the necessary package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTr1k2e-Xwym",
        "outputId": "11692b1a-da68-4768-a4cf-18173cfbe87b"
      },
      "source": [
        "!pip install abstention"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: abstention in /usr/local/lib/python3.6/dist-packages (0.1.3.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from abstention) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from abstention) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from abstention) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->abstention) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpVkHumdWTx2"
      },
      "source": [
        "Download the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFPf85JSWOfc"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3U_XH8bWOfc"
      },
      "source": [
        "#Import relevant modules and define functions for reading in the data\n",
        "import gzip\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from scipy.special import softmax\n",
        "from abstention.calibration import TempScaling\n",
        "from abstention.label_shift import EMImbalanceAdapter\n",
        "\n",
        "def read_labels(fh):\n",
        "    to_return = []\n",
        "    for line in fh:\n",
        "        the_class=int(line.rstrip())\n",
        "        to_add = np.zeros(10)\n",
        "        to_add[the_class] = 1\n",
        "        to_return.append(to_add)\n",
        "    return np.array(to_return)\n",
        "\n",
        "def read_preds(fh):\n",
        "    return np.array([[float(x) for x in y.decode(\"utf-8\").rstrip().split(\"\\t\")]\n",
        "                     for y in fh])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDftlzU6WOfd"
      },
      "source": [
        "#Read in the validation set predictions and labels, as well as the predictions\n",
        "# on the (label shifted) test set\n",
        "valid_labels = read_labels(gzip.open(\"demo_valid_labels.txt.gz\", \"rb\"))\n",
        "valid_preds = read_preds(gzip.open(\"demo_valid_preds.txt.gz\", \"rb\"))\n",
        "shifted_test_preds = read_preds(gzip.open(\"demo_shifted_test_preds.txt.gz\", \"rb\"))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA8EnUvcWOfd"
      },
      "source": [
        "#Specify BCTS as the calibrator to use\n",
        "bcts_calibrator_factory = TempScaling(verbose=False, bias_positions='all')\n",
        "#Specify that we would like to use Maximum Likelihood (EM) for the label shift adaptation\n",
        "imbalance_adapter = EMImbalanceAdapter(calibrator_factory=\n",
        "                                       bcts_calibrator_factory)\n",
        "#Get the function that will do the label shift adaptation; \"valid\" is for\n",
        "# the validation set\n",
        "imbalance_adapter_func = imbalance_adapter(valid_labels=valid_labels,\n",
        "                          tofit_initial_posterior_probs=shifted_test_preds,\n",
        "                          valid_posterior_probs=valid_preds)\n",
        "#Get the adapted test-set predictions\n",
        "adapted_shifted_test_preds = imbalance_adapter_func(shifted_test_preds)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zsm221-WOfd",
        "outputId": "9b41ac17-d24d-42bf-db49-4918d6d4164c"
      },
      "source": [
        "#Let's evaluate the improvement in performance due to domain adaptation\n",
        "shifted_test_labels = read_labels(gzip.open(\"demo_shifted_test_labels.txt.gz\", \"rb\"))\n",
        "test_accuracy = np.mean(np.argmax(shifted_test_labels,axis=-1)==np.argmax(shifted_test_preds,axis=-1))\n",
        "adapted_test_accuracy = np.mean(np.argmax(shifted_test_labels,axis=-1)==np.argmax(adapted_shifted_test_preds,axis=-1))\n",
        "print(test_accuracy, adapted_test_accuracy)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.707 0.986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncoOivjZqMl4"
      },
      "source": [
        "For reference, this is the code that was used to generate the `demo_*` files\n",
        "\n",
        "```\n",
        "import gzip\n",
        "import glob\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "def sample_from_probs_arr(arr_with_probs):\n",
        "    rand_num = np.random.random()\n",
        "    cdf_so_far = 0\n",
        "    for (idx, prob) in enumerate(arr_with_probs):\n",
        "        cdf_so_far += prob\n",
        "        if (cdf_so_far >= rand_num\n",
        "            or idx == (len(arr_with_probs) - 1)):  # need the\n",
        "            # letterIdx==(len(row)-1) clause because of potential floating point errors\n",
        "            # that mean arrWithProbs doesn't sum to 1\n",
        "            return idx\n",
        "\n",
        "\n",
        "def draw_test_indices(total_to_return, label_proportions):\n",
        "    indices_to_use = []\n",
        "    for class_index, class_proportion in enumerate(label_proportions):\n",
        "        indices_to_use.extend(np.random.choice(\n",
        "                TEST_CLASS_TO_INDICES[class_index],\n",
        "                int(total_to_return*class_proportion),\n",
        "                replace=True))\n",
        "    for i in range(total_to_return-len(indices_to_use)):\n",
        "        class_index = sample_from_probs_arr(label_proportions)\n",
        "        indices_to_use.append(\n",
        "            np.random.choice(TEST_CLASS_TO_INDICES[class_index]))\n",
        "    return indices_to_use\n",
        "\n",
        "\n",
        "def write_preds(preds, filename):\n",
        "  f = open(filename,'w')\n",
        "  for pred in preds:\n",
        "    f.write(\"\\t\".join([str(x) for x in pred])+\"\\n\") \n",
        "  f.close()\n",
        "\n",
        "\n",
        "def write_labels(labels, filename):\n",
        "  f = open(filename,'w')\n",
        "  f.write(\"\\n\".join([str(np.argmax(x, axis=-1)) for x in labels]))\n",
        "  f.close()\n",
        "\n",
        "\n",
        "def read_labels(fh):\n",
        "    to_return = []\n",
        "    for line in fh:\n",
        "        the_class=int(line.rstrip())\n",
        "        to_add = np.zeros(10)\n",
        "        to_add[the_class] = 1\n",
        "        to_return.append(to_add)\n",
        "    return np.array(to_return)\n",
        "\n",
        "\n",
        "def read_preds(fh):\n",
        "    return np.array([[float(x) for x in y.decode(\"utf-8\").rstrip().split(\"\\t\")]\n",
        "                     for y in fh])\n",
        "\n",
        "\n",
        "!wget https://zenodo.org/record/3406662/files/test_labels.txt.gz?download?=1 -O test_labels.txt.gz\n",
        "!wget https://zenodo.org/record/3406662/files/testpreacts_model_cifar10_balanced_seed-0_bestbefore-100_currentepoch-100_valacc-91_vgg.txt.gz?download=1 -O testpreacts_model_cifar10_balanced_seed-0_bestbefore-100_currentepoch-100_valacc-91_vgg.txt.gz\n",
        "!wget https://zenodo.org/record/3406662/files/validpreacts_model_cifar10_balanced_seed-0_bestbefore-100_currentepoch-100_valacc-91_vgg.txt.gz?download=1 -O validpreacts_model_cifar10_balanced_seed-0_bestbefore-100_currentepoch-100_valacc-91_vgg.txt.gz\n",
        "!wget https://zenodo.org/record/3406662/files/valid_labels.txt.gz?download?=1 -O demo_valid_labels.txt.gz\n",
        "\n",
        "\n",
        "test_labels = read_labels(gzip.open(\"test_labels.txt.gz\"))\n",
        "test_preds = softmax(read_preds(gzip.open(\n",
        "  \"testpreacts_model_cifar10_balanced_seed-0_bestbefore-100_currentepoch-100_valacc-91_vgg.txt.gz\")),\n",
        "                       axis=1)\n",
        "valid_preds = softmax(read_preds(gzip.open(\n",
        "    \"validpreacts_model_cifar10_balanced_seed-0_bestbefore-100_currentepoch-100_valacc-91_vgg.txt.gz\")),\n",
        "                      axis=1)\n",
        "\n",
        "\n",
        "dirichlet_alpha = 0.1\n",
        "samplesize = 1000\n",
        "dirichlet_dist = np.random.RandomState(123).dirichlet(\n",
        "                  [dirichlet_alpha for x in range(10)])\n",
        "\n",
        "TEST_CLASS_TO_INDICES = defaultdict(list)\n",
        "for index,row in enumerate(test_labels):\n",
        "    row_label = np.argmax(row)\n",
        "    TEST_CLASS_TO_INDICES[row_label].append(index)\n",
        "\n",
        "test_indices = draw_test_indices(total_to_return=samplesize,\n",
        "                                 label_proportions=dirichlet_dist)\n",
        "shifted_test_labels = test_labels[test_indices]\n",
        "shifted_test_preds = test_preds[test_indices]\n",
        "\n",
        "write_preds(preds=valid_preds, filename=\"demo_valid_preds.txt\")\n",
        "write_preds(preds=shifted_test_preds, filename=\"demo_shifted_test_preds.txt\")\n",
        "write_labels(labels=shifted_test_labels, filename=\"demo_shifted_test_labels.txt\")\n",
        "!gzip -f *.txt\n",
        "```\n",
        "\n"
      ]
    }
  ]
}